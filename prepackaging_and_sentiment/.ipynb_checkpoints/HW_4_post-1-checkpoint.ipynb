{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4: Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-block alert-warning\">Each assignment needs to be completed independently. Never ever copy others' work (even with minor modification, e.g. changing variable names). Anti-Plagiarism software will be used to check all submissions. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "\n",
    "In this assignment, we'll use what we learned in preprocessing module to compare ChatGPT-generated text with human-generated answers. A dataset with 200 questions and answers has been provided for you to use. The dataset can be found at https://huggingface.co/datasets/Hello-SimpleAI/HC3.\n",
    "\n",
    "\n",
    "Please follow the instruction below to do the assessment step by step and answer all analysis questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>chatgpt_answer</th>\n",
       "      <th>human_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What happens if a parking ticket is lost / des...</td>\n",
       "      <td>If a parking ticket is lost or destroyed befor...</td>\n",
       "      <td>In my city you also get something by mail to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why the waves do n't interfere ? first , I 'm ...</td>\n",
       "      <td>Interference is the phenomenon that occurs whe...</td>\n",
       "      <td>They do actually . That 's why a microwave ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is it possible to influence a company's action...</td>\n",
       "      <td>Yes, it is possible to influence a company's a...</td>\n",
       "      <td>Yes and no. This really should be taught at ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why do taxpayers front the bill for sports sta...</td>\n",
       "      <td>Sports stadiums are usually built with public ...</td>\n",
       "      <td>That 's the bargaining chip that team owners u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why do clothing stores generally have a ton of...</td>\n",
       "      <td>There are a few reasons why clothing stores ma...</td>\n",
       "      <td>Your observation is almost certainly a matter ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What happens if a parking ticket is lost / des...   \n",
       "1  why the waves do n't interfere ? first , I 'm ...   \n",
       "2  Is it possible to influence a company's action...   \n",
       "3  Why do taxpayers front the bill for sports sta...   \n",
       "4  Why do clothing stores generally have a ton of...   \n",
       "\n",
       "                                      chatgpt_answer  \\\n",
       "0  If a parking ticket is lost or destroyed befor...   \n",
       "1  Interference is the phenomenon that occurs whe...   \n",
       "2  Yes, it is possible to influence a company's a...   \n",
       "3  Sports stadiums are usually built with public ...   \n",
       "4  There are a few reasons why clothing stores ma...   \n",
       "\n",
       "                                        human_answer  \n",
       "0  In my city you also get something by mail to t...  \n",
       "1  They do actually . That 's why a microwave ove...  \n",
       "2  Yes and no. This really should be taught at ju...  \n",
       "3  That 's the bargaining chip that team owners u...  \n",
       "4  Your observation is almost certainly a matter ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"qa.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Tokenize function\n",
    "\n",
    "Define a function `tokenize(docs, lemmatized = True, remove_stopword = True, remove_punct = True)`  as follows:\n",
    "   - Take three parameters: \n",
    "       - `docs`: a list of documents (e.g. questions)\n",
    "       - `lemmatized`: an optional boolean parameter to indicate if tokens are lemmatized. The default value is True (i.e. tokens are lemmatized).\n",
    "       - `remove_stopword`: an optional bookean parameter to remove stop words. The default value is True (i.e. remove stop words). \n",
    "   - Split each input document into unigrams and also clean up tokens as follows:\n",
    "       - if `lemmatized` is turned on, lemmatize all unigrams.\n",
    "       - if `remove_stopword` is set to True, remove all stop words.\n",
    "       - if `remove_punct` is set to True, remove all punctuation tokens.\n",
    "       - remove all empty tokens and lowercase all the tokens.\n",
    "   - Return the list of tokens obtained for each document after all the processing. \n",
    "   \n",
    "(Hint: you can use spacy package for this task. For reference, check https://spacy.io/api/token#attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_a_doc(doc, nlp, lemmatized=True, remove_stopword=True, remove_punct=True): \n",
    "    clean_tokens = []\n",
    "    # load current doc into spacy nlp model\n",
    "    chunks = doc.split(\"\\\\n\")\n",
    "    for chunk in chunks:\n",
    "        doc = nlp(chunk)\n",
    "    \n",
    "        # clean either lemmatized unigrams or unmodified doc tokens\n",
    "        if lemmatized:\n",
    "            clean_tokens += [token.lemma_.lower() for token in doc            # using spacy nlp params, skip token if:\n",
    "                            if (not remove_stopword or not token.is_stop)     # it is a stopword and remove_stopwords = True\n",
    "                            and (not remove_punct or not token.is_punct)      # it is punctuation and remove_punct = True\n",
    "                            and not token.lemma_.isspace()]                   # it is whitespace\n",
    "        else:\n",
    "            clean_tokens += [token.text.lower() for token in doc \n",
    "                            if (not remove_stopword or not token.is_stop) \n",
    "                            and (not remove_punct or not token.is_punct) \n",
    "                            and not token.text.isspace()]\n",
    "        \n",
    "    return clean_tokens\n",
    "\n",
    "def tokenize(docs, lemmatized=True, remove_stopword=True, remove_punct=True):\n",
    "    # load in spacy NLP model and disable unused pipelines to reduce processing time/memory space\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "    # tokenize each doc in the corpus using specified params for lemmatization and removal conditions\n",
    "    tokens = [tokenize_a_doc(doc, nlp, lemmatized, remove_stopword, remove_punct) for doc in docs]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function with different parameter configuration and observe the differences in the resulting tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What happens if a parking ticket is lost / destroyed before the owner is aware of the ticket , and it goes unpaid ? I 've always been curious . Please explain like I'm five.\n",
      "\n",
      "1.lemmatized=True, remove_stopword=False, remove_punct = True:\n",
      " [['what', 'happen', 'if', 'a', 'parking', 'ticket', 'be', 'lose', 'destroy', 'before', 'the', 'owner', 'be', 'aware', 'of', 'the', 'ticket', 'and', 'it', 'go', 'unpaid', 'i', 've', 'always', 'be', 'curious', 'please', 'explain', 'like', 'i', 'be', 'five']]\n",
      "\n",
      "2.lemmatized=True, remove_stopword=True, remove_punct = True:\n",
      " [['happen', 'parking', 'ticket', 'lose', 'destroy', 'owner', 'aware', 'ticket', 'go', 'unpaid', 've', 'curious', 'explain', 'like']]\n",
      "\n",
      "3.lemmatized=False, remove_stopword=False, remove_punct = True:\n",
      " [['what', 'happens', 'if', 'a', 'parking', 'ticket', 'is', 'lost', 'destroyed', 'before', 'the', 'owner', 'is', 'aware', 'of', 'the', 'ticket', 'and', 'it', 'goes', 'unpaid', 'i', 've', 'always', 'been', 'curious', 'please', 'explain', 'like', 'i', \"'m\", 'five']]\n",
      "\n",
      "4.lemmatized=False, remove_stopword=False, remove_punct = False:\n",
      " [['what', 'happens', 'if', 'a', 'parking', 'ticket', 'is', 'lost', '/', 'destroyed', 'before', 'the', 'owner', 'is', 'aware', 'of', 'the', 'ticket', ',', 'and', 'it', 'goes', 'unpaid', '?', 'i', \"'\", 've', 'always', 'been', 'curious', '.', 'please', 'explain', 'like', 'i', \"'m\", 'five', '.']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For simplicity, We will test on document\n",
    "\n",
    "print(data[\"question\"].iloc[0] + \"\\n\")\n",
    "\n",
    "print(f\"1.lemmatized=True, remove_stopword=False, remove_punct = True:\\n \\\n",
    "{tokenize(data['question'].iloc[0:1], lemmatized=True, remove_stopword=False, remove_punct = True)}\\n\")\n",
    "\n",
    "print(f\"2.lemmatized=True, remove_stopword=True, remove_punct = True:\\n \\\n",
    "{tokenize(data['question'].iloc[0:1], lemmatized=True, remove_stopword=True, remove_punct = True)}\\n\")\n",
    "\n",
    "print(f\"3.lemmatized=False, remove_stopword=False, remove_punct = True:\\n \\\n",
    "{tokenize(data['question'].iloc[0:1], lemmatized=False, remove_stopword=False, remove_punct = True)}\\n\")\n",
    "\n",
    "print(f\"4.lemmatized=False, remove_stopword=False, remove_punct = False:\\n \\\n",
    "{tokenize(data['question'].iloc[0:1], lemmatized=False, remove_stopword=False, remove_punct = False)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Sentiment Analysis\n",
    "\n",
    "\n",
    "Let's check if there is any difference in sentiment between ChatGPT-generated and human-generated answers.\n",
    "\n",
    "\n",
    "Define a function `compute_sentiment(generated, reference, pos, neg )` as follows:\n",
    "- take four parameters:\n",
    "    - `gen_tokens` is the tokenized ChatGPT-generated answers by the `tokenize` function in Q1.\n",
    "    - `ref_tokens` is the tokenized human-generated answers by the `tokenize` function in Q1.\n",
    "    - `pos` (`neg`) is the lists of positive (negative) words, which can be find in Canvas preprocessing module.\n",
    "- for each ChatGPT-generated or human-generated answer, compute the sentiment as `(#pos - #neg )/(#pos + #neg)`, where `#pos`(`#neg`) is the number of positive (negative) words found in each answer. If an answer contains none of the positive or negative words, set the sentiment to 0.\n",
    "- return the sentiment of ChatGPT-generated and human-generated answers as two columns of DataFrame.\n",
    "\n",
    "\n",
    "Analysis: \n",
    "- Try different tokenization parameter configurations (lemmatized, remove_stopword, remove_punct), and observe how sentiment results change.\n",
    "- Do you think, in general, which tokenization configuration should be used? Why does this combination make the most senese?\n",
    "- Do you think, overall, ChatGPT-generated answers are more posive or negative than human-generated ones? Use data to support your conclusion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent(target, pos, neg):\n",
    "    p = sum(1 for word in target if word in pos)\n",
    "    n = sum(1 for word in target if word in neg)\n",
    "    if p + n != 0:\n",
    "        sentiment = (p - n) / (p + n)\n",
    "    else:\n",
    "        sentiment = 0\n",
    "    return sentiment\n",
    "\n",
    "def compute_sentiment(gen_tokens, ref_tokens, pos, neg):\n",
    "    \n",
    "    tokens = lambda token_list: [sent(sublist, pos, neg) for sublist in token_list]\n",
    "    result = pd.DataFrame({'gen_sentiment': tokens(gen_tokens), 'ref_sentiment': tokens(ref_tokens)})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_tokens = tokenize(data[\"chatgpt_answer\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "ref_tokens = tokenize(data[\"human_answer\"], lemmatized=False, remove_stopword=False, remove_punct = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abundance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abundant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0         a+\n",
       "1     abound\n",
       "2    abounds\n",
       "3  abundance\n",
       "4   abundant"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-faced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-faces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abolish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abominable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0     2-faced\n",
       "1     2-faces\n",
       "2    abnormal\n",
       "3     abolish\n",
       "4  abominable"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = pd.read_csv(\"positive-words.txt\", header = None)\n",
    "pos.head()\n",
    "\n",
    "neg = pd.read_csv(\"negative-words.txt\", header = None)\n",
    "neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_sentiment</th>\n",
       "      <th>ref_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.777778</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gen_sentiment  ref_sentiment\n",
       "0       0.000000      -0.500000\n",
       "1      -0.777778       0.076923\n",
       "2       0.666667       0.200000\n",
       "3       1.000000       0.200000\n",
       "4       0.600000      -0.333333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = compute_sentiment(gen_tokens, \n",
    "                           ref_tokens, \n",
    "                           pos[0].values,\n",
    "                           neg[0].values)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1462586239453829"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10279.5, 0.0011456573663914912)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "(result['gen_sentiment'] - result['ref_sentiment']).mean()\n",
    "\n",
    "res = wilcoxon(result['gen_sentiment'] - result['ref_sentiment'], alternative='greater')\n",
    "res.statistic, res.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14665715815970656"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10403.0, 0.0010660004805700114)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "(result['gen_sentiment'] - result['ref_sentiment']).mean()\n",
    "\n",
    "res = wilcoxon(result['gen_sentiment'] - result['ref_sentiment'], alternative='greater')\n",
    "res.statistic, res.pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: Performance Evaluation\n",
    "\n",
    "\n",
    "Next, we evaluate how accurate the ChatGPT-generated answers are, compared to the human-generated answers. One widely used method is to calculate the `precision` and `recall` of n-grams. For simplicity, we only calculate bigrams here. You can try unigram, trigram, or n-grams in the same way.\n",
    "\n",
    "\n",
    "Define a funtion `bigram_precision_recall(gen_tokens, ref_tokens)` as follows:\n",
    "- take two parameters:\n",
    "    - `gen_tokens` is the tokenized ChatGPT-generated answers by the `tokenize` function in Q1.\n",
    "    - `ref_tokens` is the tokenized human answers by the `tokenize` function in Q1.\n",
    "- generate bigrams from each tokenized document in `gen_tokens` and `ref_tokens`\n",
    "- for each pair of ChatGPT-generated and human answers, find the overlapping bigrams between them\n",
    "- compute `precision` as the number of overlapping bigrams divided by the total number of bigrams from the ChatGPT-generated answer. In other words, the bigram is considered as a predicted value. The `precision` measures the percentage of correctly generated bigrams out of all generated bigrams.\n",
    "- compute `recall` as the number of overlapping bigrams divided by the total number of bigrams from the human answer. In other words, the `recall` measures the percentage of bigrams from the human answer can be successfully retrieved.\n",
    "- return the precision and recall for each pair of answers.\n",
    "\n",
    "\n",
    "Analysis: \n",
    "- Try different tokenization parameter configurations (lemmatized, remove_stopword, remove_punct), and observe how precison and recall change.\n",
    "- Do you think, in general, which tokenization configuration should be used? Why does this combination make the most senese?\n",
    "- Do you think, overall, ChatGPT is able to mimic human in answering these questions?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_precision_recall(gen_tokens, ref_tokens):\n",
    "    result = pd.DataFrame(columns = ['overlapping','precision','recall'])\n",
    "    \n",
    "    gen_bigrams = [list(nltk.bigrams(tokens)) for tokens in gen_tokens]\n",
    "    ref_bigrams = [list(nltk.bigrams(tokens)) for tokens in ref_tokens]\n",
    "\n",
    "    bigrams = list(zip(gen_bigrams, ref_bigrams))\n",
    "\n",
    "    overlapping = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    for gen, ref in bigrams:\n",
    "        overlap = [tup1 for tup1 in gen for tup2 in ref if tup1 == tup2]\n",
    "        overlapping.append(list(set(overlap)))\n",
    "\n",
    "        precision.append(len(overlap)/len(gen))\n",
    "        recall.append(len(overlap)/len(ref))\n",
    "\n",
    "    result['overlapping'] = overlapping\n",
    "    result['precision'] = precision\n",
    "    result['recall'] = recall\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overlapping</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(to, pay), (it, goes)]</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.042553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(radio, stations), (can, cancel), (out, of), ...</td>\n",
       "      <td>0.065421</td>\n",
       "      <td>0.031390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(shareholders, to), (to, influence), (to, vot...</td>\n",
       "      <td>0.230216</td>\n",
       "      <td>0.096677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(be, the), (to, be), (the, local)]</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>0.051724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(result, ,), (., if), (a, result), (as, a), (...</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.072165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         overlapping  precision    recall\n",
       "0                            [(to, pay), (it, goes)]   0.016807  0.042553\n",
       "1  [(radio, stations), (can, cancel), (out, of), ...   0.065421  0.031390\n",
       "2  [(shareholders, to), (to, influence), (to, vot...   0.230216  0.096677\n",
       "3                [(be, the), (to, be), (the, local)]   0.017647  0.051724\n",
       "4  [(result, ,), (., if), (a, result), (as, a), (...   0.028571  0.072165"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = bigram_precision_recall(gen_tokens, \n",
    "                                 ref_tokens)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision    0.110050\n",
       "recall       0.165531\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[[\"precision\", \"recall\"]].mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overlapping</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(it, goes), (to, pay)]</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.042553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(can, cancel), (out, of), (radio, stations), ...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.015695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(to, influence), (a, company), (to, vote), (t...</td>\n",
       "      <td>0.143885</td>\n",
       "      <td>0.060423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(to, be), (the, local), (be, the)]</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>0.051724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(., as), (as, a), (a, result), (result, ,), (...</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.072165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         overlapping  precision    recall\n",
       "0                            [(it, goes), (to, pay)]   0.016807  0.042553\n",
       "1  [(can, cancel), (out, of), (radio, stations), ...   0.033333  0.015695\n",
       "2  [(to, influence), (a, company), (to, vote), (t...   0.143885  0.060423\n",
       "3                [(to, be), (the, local), (be, the)]   0.017647  0.051724\n",
       "4  [(., as), (as, a), (a, result), (result, ,), (...   0.028571  0.072165"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = bigram_precision_recall(gen_tokens, \n",
    "                                 ref_tokens)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision    0.074530\n",
       "recall       0.132274\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[[\"precision\", \"recall\"]].mean(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 Compute TF-IDF\n",
    "\n",
    "Define a function `compute_tf_idf(tokenized_docs)` as follows: \n",
    "- Take paramter `tokenized_docs`, i.e., a list of tokenized documents by `tokenize` function in Q1\n",
    "- Calculate tf_idf weights as shown in lecture notes (Hint: feel free to reuse the code segment in Lecture Notes (II))\n",
    "- Return the smoothed normalized `tf_idf` array, where each row stands for a document and each column denotes a word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 1.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_tokens = {idx:nltk.FreqDist(tokens) for idx,tokens in enumerate(corpus)}\n",
    "dtm=pd.DataFrame.from_dict(docs_tokens, orient=\"index\").fillna(0).sort_index(axis = 0)\n",
    "tf=dtm.values\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tfidf(docs):\n",
    "    # step 2. process all documents to get list of token list\n",
    "    docs_tokens = {idx:nltk.FreqDist(tokens) for idx,tokens in enumerate(docs)}\n",
    "\n",
    "    # step 3. get document-term matrix\n",
    "    dtm=pd.DataFrame.from_dict(docs_tokens, orient=\"index\").fillna(0).sort_index(axis = 0)\n",
    "      \n",
    "    # step 4. get normalized term frequency (tf) matrix        \n",
    "    tf=dtm.values\n",
    "    doc_len=tf.sum(axis=1, keepdims=True)\n",
    "    tf=np.divide(tf, doc_len)\n",
    "    \n",
    "    # step 5. get idf\n",
    "    df=np.where(tf>0,1,0)\n",
    "    #idf=np.log(np.divide(len(docs), \\\n",
    "    #    np.sum(df, axis=0)))+1\n",
    "\n",
    "    smoothed_idf=np.log(np.divide(len(docs)+1, np.sum(df, axis=0)+1))+1    \n",
    "    smoothed_tf_idf=normalize(tf*smoothed_idf)\n",
    "    \n",
    "    return smoothed_tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different tokenization options to see how these options affect TFIDF matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.lemmatized=True, remove_stopword=False, remove_punct = True\n",
      " Shape: (200, 1438)\n",
      "\n",
      "2.lemmatized=True, remove_stopword=True, remove_punct = True:\n",
      " Shape: (200, 1271)\n",
      "\n",
      "3.lemmatized=False, remove_stopword=False, remove_punct = True:\n",
      " Shape: (200, 1643)\n",
      "\n",
      "4.lemmatized=False, remove_stopword=False, remove_punct = False:\n",
      " Shape: (200, 1665)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test tfidf generation using questions\n",
    "\n",
    "question_tokens = tokenize(data[\"question\"], lemmatized=True, remove_stopword=False, remove_punct = True)\n",
    "dtm = compute_tfidf(question_tokens)\n",
    "print(f\"1.lemmatized=True, remove_stopword=False, remove_punct = True\\n \\\n",
    "Shape: {dtm.shape}\\n\")\n",
    "\n",
    "question_tokens = tokenize(data[\"question\"], lemmatized=True, remove_stopword=True, remove_punct = True)\n",
    "dtm = compute_tfidf(question_tokens)\n",
    "print(f\"2.lemmatized=True, remove_stopword=True, remove_punct = True:\\n \\\n",
    "Shape: {dtm.shape}\\n\")\n",
    "\n",
    "question_tokens = tokenize(data[\"question\"], lemmatized=False, remove_stopword=False, remove_punct = True)\n",
    "dtm = compute_tfidf(question_tokens)\n",
    "print(f\"3.lemmatized=False, remove_stopword=False, remove_punct = True:\\n \\\n",
    "Shape: {dtm.shape}\\n\")\n",
    "\n",
    "question_tokens = tokenize(data[\"question\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "dtm = compute_tfidf(question_tokens)\n",
    "print(f\"4.lemmatized=False, remove_stopword=False, remove_punct = False:\\n \\\n",
    "Shape: {dtm.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.lemmatized=True, remove_stopword=False, remove_punct = True\n",
      " Shape: (200, 1435)\n",
      "\n",
      "2.lemmatized=True, remove_stopword=True, remove_punct = True:\n",
      " Shape: (200, 1269)\n",
      "\n",
      "3.lemmatized=False, remove_stopword=False, remove_punct = True:\n",
      " Shape: (200, 1643)\n",
      "\n",
      "4.lemmatized=False, remove_stopword=False, remove_punct = False:\n",
      " Shape: (200, 1665)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test tfidf generation using questions\n",
    "\n",
    "question_tokens = tokenize(data[\"question\"], lemmatized=True, remove_stopword=False, remove_punct = True)\n",
    "dtm = compute_tfidf(question_tokens)\n",
    "print(f\"1.lemmatized=True, remove_stopword=False, remove_punct = True:\\n \\\n",
    "Shape: {dtm.shape}\\n\")\n",
    "\n",
    "question_tokens = tokenize(data[\"question\"], lemmatized=True, remove_stopword=True, remove_punct = True)\n",
    "dtm = compute_tfidf(question_tokens)\n",
    "print(f\"2.lemmatized=True, remove_stopword=True, remove_punct = True:\\n \\\n",
    "Shape: {dtm.shape}\\n\")\n",
    "\n",
    "question_tokens = tokenize(data[\"question\"], lemmatized=False, remove_stopword=False, remove_punct = True)\n",
    "dtm = compute_tfidf(question_tokens)\n",
    "print(f\"3.lemmatized=False, remove_stopword=False, remove_punct = True:\\n \\\n",
    "Shape: {dtm.shape}\\n\")\n",
    "\n",
    "question_tokens = tokenize(data[\"question\"], lemmatized=False, remove_stopword=False, remove_punct = False)\n",
    "dtm = compute_tfidf(question_tokens)\n",
    "print(f\"4.lemmatized=False, remove_stopword=False, remove_punct = False:\\n \\\n",
    "Shape: {dtm.shape}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. Assess similarity. \n",
    "\n",
    "\n",
    "Define a function `assess_similarity(question_tokens, gen_tokens, ref_tokens)`  as follows: \n",
    "- Take three inputs:\n",
    "   - `question_tokens`: tokenized questions by `tokenize` function in Q1\n",
    "   - `gen_tokens`: tokenized ChatGPT-generated answers by `tokenize` function in Q1\n",
    "   - `ref_tokens`: tokenized human answers by `tokenize` function in Q1\n",
    "- Concatenate these three token lists into a single list to form a corpus\n",
    "- Calculate the smoothed normalized tf_idf matrix for the concatenated list using the `compute_tfidf` function defined in Q3.\n",
    "- Split the tf_idf matrix into sub-matrices corresponding to `question_tokens`, `gen_tokens`, and `ref_tokens` respectively\n",
    "- For each question, find its similarities to the paired ChatGPT-generated answer and human answer.\n",
    "- For each pair of ChatGPT-generated answer and human answer, find their similarity\n",
    "- Print out the following:\n",
    "    - the question which has the largest similarity to the ChatGPT-generated answer.\n",
    "    - the question which has the largest similarity to the human answer.\n",
    "    - the pair of ChatGPT-generated and human answers which have the largest similarity.\n",
    "- Return a DataFrame with the three columns for the similarities among questions and answers.\n",
    "\n",
    "\n",
    "\n",
    "Analysis: \n",
    "- Try different tokenization parameter configurations (lemmatized, remove_stopword, remove_punct), and observe how similarities change.\n",
    "- Based on similarity, do you think ChatGPT-generate answers are more relevant to questions than human answers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package to calculate distance\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57054916, 0.04873125, 0.05435993, ..., 0.05525877, 0.04119335,\n",
       "        0.06083295],\n",
       "       [0.06837583, 0.53589851, 0.07290558, ..., 0.09236547, 0.05481382,\n",
       "        0.10305691],\n",
       "       [0.1187486 , 0.01299878, 0.46451491, ..., 0.08568355, 0.0288882 ,\n",
       "        0.04995915],\n",
       "       ...,\n",
       "       [0.04069226, 0.02958631, 0.03604291, ..., 0.33750164, 0.03119483,\n",
       "        0.08137021],\n",
       "       [0.0439228 , 0.05876601, 0.06815987, ..., 0.06023432, 0.50735979,\n",
       "        0.06542159],\n",
       "       [0.10568441, 0.07956869, 0.08638208, ..., 0.08546416, 0.1024627 ,\n",
       "        0.47311868]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([  0, 177], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity=1-pairwise_distances(tfidf_question, tfidf_gen, metric = 'cosine')\n",
    "similarity\n",
    "\n",
    "# find top doc similar to the first one\n",
    "# Note the diagonal value is 1, which is the largest\n",
    "\n",
    "np.argsort(similarity)[:,::-1][0,0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7341</th>\n",
       "      <th>7342</th>\n",
       "      <th>7343</th>\n",
       "      <th>7344</th>\n",
       "      <th>7345</th>\n",
       "      <th>7346</th>\n",
       "      <th>7347</th>\n",
       "      <th>7348</th>\n",
       "      <th>7349</th>\n",
       "      <th>7350</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 7351 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3     4     5     6     7     8     9     ...  7341  \\\n",
       "0    0.10  0.19  0.09  0.06  0.26  0.49  0.24  0.22  0.27  0.15  ...  0.00   \n",
       "1    0.08  0.00  0.00  0.00  0.00  0.00  0.13  0.00  0.00  0.00  ...  0.00   \n",
       "2    0.00  0.00  0.00  0.12  0.00  0.00  0.13  0.00  0.00  0.00  ...  0.00   \n",
       "3    0.00  0.00  0.00  0.07  0.00  0.00  0.15  0.00  0.00  0.00  ...  0.00   \n",
       "4    0.00  0.00  0.00  0.10  0.00  0.00  0.05  0.00  0.00  0.00  ...  0.00   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "595  0.09  0.00  0.04  0.09  0.00  0.00  0.08  0.00  0.00  0.00  ...  0.00   \n",
       "596  0.00  0.00  0.00  0.07  0.00  0.00  0.03  0.00  0.00  0.00  ...  0.00   \n",
       "597  0.00  0.00  0.00  0.09  0.00  0.00  0.02  0.00  0.00  0.00  ...  0.00   \n",
       "598  0.00  0.00  0.00  0.08  0.00  0.00  0.00  0.00  0.00  0.07  ...  0.13   \n",
       "599  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n",
       "\n",
       "     7342  7343  7344  7345  7346  7347  7348  7349  7350  \n",
       "0    0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "1    0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "2    0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "3    0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "4    0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "595  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "596  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "597  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "598  0.13  0.26  0.13  0.13  0.13  0.13  0.13  0.00  0.00  \n",
       "599  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.26  0.26  \n",
       "\n",
       "[600 rows x 7351 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For better visualization, let's make the tf-idf array a dataframe\n",
    "pd.options.display.float_format = '{:,.2f}'.format # set format for float\n",
    "\n",
    "pd.DataFrame(tf_idf)\n",
    "# the dtm dataframe we created in Step 3 has each word as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the nested list\n",
    "# Concatenate the three lists into a single list\n",
    "corpus = []\n",
    "corpus.extend(question_tokens)\n",
    "corpus.extend(gen_tokens)\n",
    "corpus.extend(ref_tokens)\n",
    "tf_idf = compute_tfidf(corpus)\n",
    "\n",
    "n_question_tokens = len(question_tokens)\n",
    "n_gen_tokens = len(gen_tokens)\n",
    "n_ref_tokens = len(ref_tokens)\n",
    "\n",
    "tfidf_question = tf_idf[:n_question_tokens]\n",
    "tfidf_gen = tf_idf[n_question_tokens:n_question_tokens + n_gen_tokens]\n",
    "tfidf_ref = tf_idf[-n_ref_tokens:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def assess_similarity(question_tokens, gen_tokens, ref_tokens):\n",
    "\n",
    "    # Concatenate the three lists into a single list\n",
    "    corpus = []\n",
    "    corpus.extend(question_tokens)\n",
    "    corpus.extend(gen_tokens)\n",
    "    corpus.extend(ref_tokens)\n",
    "    \n",
    "    tf_idf = compute_tfidf(corpus)\n",
    "    # Split the tf-idf matrix\n",
    "    n_question_tokens = len(question_tokens)\n",
    "    n_gen_tokens = len(gen_tokens)\n",
    "    n_ref_tokens = len(ref_tokens)\n",
    "    \n",
    "    tfidf_question_tokens = tf_idf[:n_question_tokens]\n",
    "    tfidf_gen_tokens = tf_idf[n_question_tokens:n_question_tokens + n_gen_tokens]\n",
    "    tfidf_ref_tokens = tf_idf[-n_ref_tokens:]\n",
    "\n",
    "    # Calculate the similarities\n",
    "    sim_question_gen = cosine_similarity(tfidf_question_tokens, tfidf_gen_tokens)\n",
    "    sim_question_ref = cosine_similarity(tfidf_question_tokens, tfidf_ref_tokens)\n",
    "    sim_gen_ref = cosine_similarity(tfidf_gen_tokens, tfidf_ref_tokens)\n",
    "\n",
    "    # Find the maximum similarities\n",
    "    max_sim_question_gen = np.max(sim_question_gen, axis=1)\n",
    "#     max_sim_question_gen_idx = np.argmax(sim_question_gen, axis=1)\n",
    "    max_sim_question_ref = np.max(sim_question_ref, axis=1)\n",
    "#     max_sim_question_ref_idx = np.argmax(sim_question_ref, axis=1)\n",
    "    max_sim_gen_ref = np.max(sim_gen_ref)\n",
    "#     max_sim_gen_ref_idx = np.unravel_index(np.argmax(sim_gen_ref, axis=None), sim_gen_ref.shape)\n",
    "    \n",
    "    # Return a DataFrame\n",
    "    result = pd.DataFrame({\n",
    "        'question_gen_sim': max_sim_question_gen,\n",
    "        'question_ref_sim': max_sim_question_ref,\n",
    "        'gen_ref_sim': max_sim_gen_ref\n",
    "    })\n",
    "    return result\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sim_question_gen</th>\n",
       "      <th>sim_question_ref</th>\n",
       "      <th>sim_gen_ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>2.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.306688</td>\n",
       "      <td>0.210218</td>\n",
       "      <td>6.801671e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.116436</td>\n",
       "      <td>0.103345</td>\n",
       "      <td>1.780814e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.082671</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>6.801671e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.215031</td>\n",
       "      <td>0.138806</td>\n",
       "      <td>6.801671e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.293052</td>\n",
       "      <td>0.173668</td>\n",
       "      <td>6.801671e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.387031</td>\n",
       "      <td>0.246901</td>\n",
       "      <td>6.801671e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.742086</td>\n",
       "      <td>0.675172</td>\n",
       "      <td>6.801671e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sim_question_gen  sim_question_ref   sim_gen_ref\n",
       "count        200.000000        200.000000  2.000000e+02\n",
       "mean           0.306688          0.210218  6.801671e-01\n",
       "std            0.116436          0.103345  1.780814e-15\n",
       "min            0.082671          0.082353  6.801671e-01\n",
       "25%            0.215031          0.138806  6.801671e-01\n",
       "50%            0.293052          0.173668  6.801671e-01\n",
       "75%            0.387031          0.246901  6.801671e-01\n",
       "max            0.742086          0.675172  6.801671e-01"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = assess_similarity(question_tokens, gen_tokens, ref_tokens)\n",
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question          Where to find historical quotes for the Dow Jo...\n",
       "chatgpt_answer    You can find historical quotes for the Dow Jon...\n",
       "human_answer      A number of places.  First, fast and cheap, yo...\n",
       "Name: 30, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question with the largest similarity to the ChatGPT-generated answer:\n",
      " Question: Where to find historical quotes for the Dow Jones Global Total Stock Market Index? \n",
      " ChatGPT: You can find historical quotes for the Dow Jones Global Total Stock Market Index at several financial websites, such as Yahoo Finance, Google Finance, and Bloomberg. These websites allow you to view the historical performance of the index and see how it has changed over time.To find historical quotes for the Dow Jones Global Total Stock Market Index on Yahoo Finance, go to the Yahoo Finance website and enter \"Dow Jones Global Total Stock Market Index\" in the search bar. From the search results, click on the link for the Dow Jones Global Total Stock Market Index. On the resulting page, you will be able to view the current value of the index as well as historical data dating back to the index's inception.To find historical quotes for the Dow Jones Global Total Stock Market Index on Google Finance, go to the Google Finance website and enter \"Dow Jones Global Total Stock Market Index\" in the search bar. From the search results, click on the link for the Dow Jones Global Total Stock Market Index. On the resulting page, you will be able to view the current value of the index as well as a chart showing its historical performance.To find historical quotes for the Dow Jones Global Total Stock Market Index on Bloomberg, go to the Bloomberg website and enter \"Dow Jones Global Total Stock Market Index\" in the search bar. From the search results, click on the link for the Dow Jones Global Total Stock Market Index. On the resulting page, you will be able to view the current value of the index as well as a chart showing its historical performance., \n",
      " Human: A number of places.  First, fast and cheap, you can probably get this from EODData.com, as part of a historical index price download -- they have good customer service in my experience and will likely confirm it for you before you buy.  Any number of other providers can get it for you too.  Likely Capital IQ, Bloomberg, and other professional solutions. I checked a number of free sites, and Market Watch was the only that had a longer history than a few months. \n",
      "\n",
      "question_ref_sim    0.111511\n",
      "question_gen_sim    0.782898\n",
      "gen_ref_sim         0.184920\n",
      "Name: 30, dtype: float64 \n",
      "\n",
      "Question with the largest similarity to the human answer:\n",
      " Question: when the wind blows james patterson \n",
      " ChatGPT: \"When the Wind Blows\" is a novel by James Patterson, published in 1996. The book is a suspense thriller that follows a couple, Frannie and Kit, as they try to uncover the truth behind a series of strange and terrifying events that occur in their small town. The novel explores themes of government conspiracy, environmentalism, and the dangers of technology. It is the first book in the \"Maximum Ride\" series, which follows the adventures of a group of genetically enhanced young people known as the \"Flock,\" who have the ability to fly., \n",
      " Human: When the Wind Blows is a novel by James Patterson . \n",
      "\n",
      "question_ref_sim    0.871841\n",
      "question_gen_sim    0.253087\n",
      "gen_ref_sim         0.353696\n",
      "Name: 117, dtype: float64 \n",
      "\n",
      "Question with the largest similarity between ChatGPT-generated and human answers:\n",
      " Question: what was the date of pearl harbor \n",
      " ChatGPT: The attack on Pearl Harbor occurred on December 7, 1941. It was a surprise military strike by the Imperial Japanese Navy against the United States naval base at Pearl Harbor, Hawaii. The attack led to the United States entering World War II., \n",
      " Human: The attack on Pearl Harbor (called Hawaii Operation or Operation AI by the Japanese Imperial General Headquarters (Operation Z in planning) and the Battle of Pearl Harbor) was a surprise military strike conducted by the Imperial Japanese Navy against the United States naval base at Pearl Harbor , Hawaii, on the morning of December 7, 1941 (December 8 in Japan). \n",
      "\n",
      "question_ref_sim    0.419917\n",
      "question_gen_sim    0.397606\n",
      "gen_ref_sim         0.682076\n",
      "Name: 122, dtype: float64 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_ref_sim</th>\n",
       "      <th>question_gen_sim</th>\n",
       "      <th>gen_ref_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125593</td>\n",
       "      <td>0.570514</td>\n",
       "      <td>0.171820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.136946</td>\n",
       "      <td>0.535158</td>\n",
       "      <td>0.265380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.198697</td>\n",
       "      <td>0.464419</td>\n",
       "      <td>0.451627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.140980</td>\n",
       "      <td>0.418178</td>\n",
       "      <td>0.349791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.177977</td>\n",
       "      <td>0.285982</td>\n",
       "      <td>0.142059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_ref_sim  question_gen_sim  gen_ref_sim\n",
       "0          0.125593          0.570514     0.171820\n",
       "1          0.136946          0.535158     0.265380\n",
       "2          0.198697          0.464419     0.451627\n",
       "3          0.140980          0.418178     0.349791\n",
       "4          0.177977          0.285982     0.142059"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = assess_similarity(question_tokens, gen_tokens, ref_tokens)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_ref_sim</th>\n",
       "      <th>question_gen_sim</th>\n",
       "      <th>gen_ref_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.202392</td>\n",
       "      <td>0.346593</td>\n",
       "      <td>0.293754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.128555</td>\n",
       "      <td>0.116747</td>\n",
       "      <td>0.143728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020415</td>\n",
       "      <td>0.014863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.105901</td>\n",
       "      <td>0.272874</td>\n",
       "      <td>0.187289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.183565</td>\n",
       "      <td>0.347686</td>\n",
       "      <td>0.289310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.266182</td>\n",
       "      <td>0.429793</td>\n",
       "      <td>0.385834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.871841</td>\n",
       "      <td>0.782898</td>\n",
       "      <td>0.682076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_ref_sim  question_gen_sim  gen_ref_sim\n",
       "count        200.000000        200.000000   200.000000\n",
       "mean           0.202392          0.346593     0.293754\n",
       "std            0.128555          0.116747     0.143728\n",
       "min            0.000000          0.020415     0.014863\n",
       "25%            0.105901          0.272874     0.187289\n",
       "50%            0.183565          0.347686     0.289310\n",
       "75%            0.266182          0.429793     0.385834\n",
       "max            0.871841          0.782898     0.682076"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 (Bonus): Further Analysis (Open question)\n",
    "\n",
    "\n",
    "- Can you find at least three significant differences between ChatGPT-generated and human answeres? Use data to support your answer.\n",
    "- Based on these differences, are you able to design a classifier to identify ChatGPT generated answers? Implement your ideas using traditional machine learning models, such as SVM, decision trees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
